{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9b48541",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import ImageFile, Image\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "from matplotlib import pyplot as plt\n",
    "import serial\n",
    "import serial.tools.list_ports\n",
    "import time\n",
    "import io\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1110b8a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def _ssd_generate_anchors() -> np.ndarray:\n",
    "    \"\"\"\n",
    "    (reference: mediapipe/calculators/tflite/ssd_anchors_calculator.cc)\n",
    "    \"\"\"\n",
    "    layer_id = 0\n",
    "    num_layers = 4\n",
    "    strides = [8, 16, 16, 16]\n",
    "    assert len(strides) == num_layers\n",
    "    input_height = 128\n",
    "    input_width = 128\n",
    "    anchor_offset_x = 0.5\n",
    "    anchor_offset_y = 0.5\n",
    "    interpolated_scale_aspect_ratio = 1\n",
    "    anchors = []\n",
    "    while layer_id < num_layers:\n",
    "        last_same_stride_layer = layer_id\n",
    "        repeats = 0\n",
    "        while (last_same_stride_layer < num_layers and\n",
    "               strides[last_same_stride_layer] == strides[layer_id]):\n",
    "            last_same_stride_layer += 1\n",
    "            # aspect_ratios are added twice per iteration\n",
    "            repeats += 2 if interpolated_scale_aspect_ratio == 1.0 else 1\n",
    "        stride = strides[layer_id]\n",
    "        feature_map_height = input_height // stride\n",
    "        feature_map_width = input_width // stride\n",
    "        for y in range(feature_map_height):\n",
    "            y_center = (y + anchor_offset_y) / feature_map_height\n",
    "            for x in range(feature_map_width):\n",
    "                x_center = (x + anchor_offset_x) / feature_map_width\n",
    "                for _ in range(repeats):\n",
    "                    anchors.append((x_center, y_center))\n",
    "        layer_id = last_same_stride_layer\n",
    "    return np.array(anchors, dtype=np.float32)\n",
    "anchors = _ssd_generate_anchors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01a0a208",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def processImage(image):\n",
    "    original_h = image.shape[0]\n",
    "    original_w = image.shape[1]\n",
    "    \n",
    "    # RUN FACE DETECT MODEL\n",
    "    resized_image = np.reshape(tf.image.resize(image, [128,128]) / 255,[1,128,128,3])\n",
    "    interpreter = tf.lite.Interpreter(model_path=\"models/face_detection_front.tflite\")\n",
    "    interpreter.allocate_tensors()\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "    interpreter.set_tensor(input_details[0]['index'], resized_image)\n",
    "    interpreter.invoke()\n",
    "    raw_boxes = interpreter.get_tensor(output_details[0]['index'])\n",
    "    raw_scores = interpreter.get_tensor(output_details[1]['index'])\n",
    "\n",
    "    # GET HIGHEST SCORE\n",
    "    raw_scores[raw_scores < -80] = -80\n",
    "    raw_scores[raw_scores > 80] = 80\n",
    "    sigmoid_scores = 1.0 / (1.0 + np.exp(-raw_scores))\n",
    "    best_score = np.max(sigmoid_scores)\n",
    "    if best_score < 0.8:\n",
    "        return 0\n",
    "    best_index = np.argmax(sigmoid_scores)\n",
    "    \n",
    "    \n",
    "    # DECODE BOX\n",
    "    scale = 128\n",
    "    num_points = 8\n",
    "    # scale all values (applies to positions, width, and height alike)\n",
    "    face_box_center = raw_boxes[0, best_index, 0:2] / scale\n",
    "    face_box_wh = raw_boxes[0, best_index, 2:4] / scale\n",
    "    # adjust center coordinates to anchor positions\n",
    "    face_box_center += anchors[best_index]\n",
    "    # convert x_center, y_center, w, h to xmin, ymin, xmax, ymax\n",
    "    center = np.array(face_box_center)\n",
    "    half_size = face_box_wh / 2\n",
    "    [xmin, ymin] = center - half_size\n",
    "    [xmax, ymax] = center + half_size\n",
    "    # only full faces in frame\n",
    "    if (xmin<0): return 0\n",
    "    if (xmax>original_w): return 0\n",
    "    if (ymin<0): return 0\n",
    "    if (ymax>original_h): return 0\n",
    "\n",
    "    # EXTRACT FACE\n",
    "    face = image[int(ymin*original_h):int(ymax*original_h), int(xmin*original_h):int(xmax*original_h),:]\n",
    "\n",
    "    # MOBILENET INTERPRETER\n",
    "    resized_face_uint8 = np.reshape(tf.image.resize(face, [192,192]),[1,192,192,3]).astype('uint8')\n",
    "    interpreter = tf.lite.Interpreter(model_path=\"models/mobilenet_v1_0.25_192_quant.tflite\")\n",
    "    interpreter.allocate_tensors()\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "    interpreter.set_tensor(input_details[0]['index'], resized_face_uint8)\n",
    "    interpreter.invoke()\n",
    "    logits = interpreter.get_tensor(output_details[0]['index'])\n",
    "    return logits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c6d35c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ARDUINO SERIAL\n",
    "FACE_DETECTED = 0\n",
    "FACE_NOT_DETECTED = 1\n",
    "\n",
    "\n",
    "def find_arduino(port=None):\n",
    "    \"\"\"Get the name of the port that is connected to Arduino.\"\"\"\n",
    "    if port is None:\n",
    "        ports = serial.tools.list_ports.comports()\n",
    "        for p in ports:\n",
    "            if p.manufacturer is not None and \"Arduino\" in p.manufacturer:\n",
    "                port = p.device\n",
    "    return port\n",
    "\n",
    "    \n",
    "def image_stream(arduino):\n",
    "    buffer_size = 1000;\n",
    "\n",
    "    # Receive Chunks\n",
    "    length = 0\n",
    "    while arduino.inWaiting() == 0:\n",
    "        pass\n",
    "    length = int(arduino.read_until().decode())\n",
    "    \n",
    "    # Stream Chunks\n",
    "    image_bytes = bytearray()\n",
    "    chunks = length // 1000\n",
    "    x = 0\n",
    "    while x < chunks:\n",
    "        while arduino.inWaiting() < 1000:\n",
    "            pass\n",
    "        image_bytes.extend(arduino.read(1000))\n",
    "        x+=1\n",
    "    while arduino.inWaiting() < length%1000:\n",
    "        pass\n",
    "    image_bytes.extend(arduino.read(length % 1000))\n",
    "    image_PIL = Image.open(io.BytesIO(image_bytes))\n",
    "    \n",
    "    # Square off the image\n",
    "    width, height = image_PIL.size   # Get dimensions\n",
    "    left = (width - height)/2\n",
    "    top = (height - height)/2\n",
    "    right = (width + height)/2\n",
    "    bottom = (height + height)/2\n",
    "\n",
    "    image = image_PIL.crop((left, top, right, bottom))\n",
    "    image = np.array(image)\n",
    "    \n",
    "    # Turn off the stream\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5e98c713",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [72]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# SERIAL INTERFACE\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m----> 9\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[43marduino\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minWaiting\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     msg \u001b[38;5;241m=\u001b[39m arduino\u001b[38;5;241m.\u001b[39mread_until()\u001b[38;5;241m.\u001b[39mdecode()\u001b[38;5;241m.\u001b[39mrstrip()\n",
      "File \u001b[0;32m~/miniconda3/envs/TF/lib/python3.10/site-packages/serial/serialutil.py:594\u001b[0m, in \u001b[0;36mSerialBase.inWaiting\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minWaiting\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 594\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_waiting\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/TF/lib/python3.10/site-packages/serial/serialposix.py:549\u001b[0m, in \u001b[0;36mSerial.in_waiting\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[38;5;124;03m\"\"\"Return the number of bytes currently in the input buffer.\"\"\"\u001b[39;00m\n\u001b[1;32m    548\u001b[0m \u001b[38;5;66;03m#~ s = fcntl.ioctl(self.fd, termios.FIONREAD, TIOCM_zero_str)\u001b[39;00m\n\u001b[0;32m--> 549\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[43mfcntl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mioctl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTIOCINQ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTIOCM_zero_str\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m struct\u001b[38;5;241m.\u001b[39munpack(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mI\u001b[39m\u001b[38;5;124m'\u001b[39m, s)[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ESTABLISH COMMUNICATION\n",
    "port = find_arduino()\n",
    "arduino = serial.Serial(port, baudrate=500000)\n",
    "_ = arduino.read_all()\n",
    "\n",
    "\n",
    "# SERIAL INTERFACE\n",
    "while True:\n",
    "    while arduino.inWaiting() == 0:\n",
    "        pass\n",
    "    msg = arduino.read_until().decode().rstrip()\n",
    "    print(msg)\n",
    "    \n",
    "    if (msg == \"CMD: STREAM IMAGE\"):\n",
    "        image = image_stream(arduino)\n",
    "        logits = processImage(image)\n",
    "        if type(logits) == np.ndarray:\n",
    "            arduino.write(bytes([FACE_DETECTED]))\n",
    "        else:\n",
    "            arduino.write(bytes([FACE_NOT_DETECTED]))\n",
    "    \n",
    "    if (msg == \"CMD: STREAM LOGITS\"):\n",
    "        arduino.write(bytes(logits))\n",
    "    \n",
    "    if (msg == \"NANO-> CV COMPLETE\"):\n",
    "        clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "228804cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b''"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arduino.read_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53308f70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
